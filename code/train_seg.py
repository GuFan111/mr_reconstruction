import os
os.environ['OMP_NUM_THREADS'] = '1'
import torch
from torch.optim.lr_scheduler import CosineAnnealingLR
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from monai.losses import GeneralizedDiceLoss, DiceCELoss
from monai.metrics import DiceMetric
from monai.utils import set_determinism
from monai.inferers import sliding_window_inference
from monai.transforms import KeepLargestConnectedComponent
from monai.data import decollate_batch

# å¯¼å…¥ä½ æ–°å†™çš„ Dataset
from dataset_seg import AMOS_Seg_Dataset
# å¯¼å…¥ MedNeXt å·¥åŽ‚å‡½æ•°
from models.mednext.create_mednext_v1 import create_mednext_v1

# é…ç½®
class Config:
    img_root = '/root/autodl-tmp/Proj/data/amos_mri_npy'
    label_root = '/root/autodl-tmp/Proj/data/amos_mri_label_npy'
    save_dir = './logs/mednext_seg_v1'
    # pretrained_path = './logs/mednext_seg_v1/best_metric_model.pth'
    pretrained_path = None
    batch_size = 1 # æ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼ŒMedNeXt-S æ¯”è¾ƒè½»é‡ï¼Œ2-4 åº”è¯¥æ²¡é—®é¢˜
    lr = 1e-3
    epochs = 100
    crop_size = (160, 160, 96) # è®­ç»ƒæ—¶çš„ Patch å¤§å°
    num_classes = 16 # AMOS ä¹Ÿæ˜¯ 16 ç±» (å«èƒŒæ™¯)

def train():
    os.makedirs(Config.save_dir, exist_ok=True)
    set_determinism(seed=0)
    
    # 1. æ•°æ®åŠ è½½
    train_ds = AMOS_Seg_Dataset(Config.img_root, Config.label_root, split='train', crop_size=Config.crop_size)
    val_ds = AMOS_Seg_Dataset(Config.img_root, Config.label_root, split='val')
    
    train_loader = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    # éªŒè¯é›† Batch Size è®¾ä¸º 1ï¼Œå› ä¸ºå…¨å›¾å°ºå¯¸è¾ƒå¤§
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)
    
    # 2. æ¨¡åž‹åˆå§‹åŒ– (MedNeXt Small)
    model = create_mednext_v1(
        num_input_channels=1,
        num_classes=Config.num_classes,
        model_id='S',             # S: Small, M: Medium
        kernel_size=3,            # 3x3x3 å·ç§¯
        deep_supervision=True     # å¼€å¯æ·±ç›‘ç£
    ).cuda()

    if Config.pretrained_path and os.path.exists(Config.pretrained_path):
        print(f"Loading pretrained weights from {Config.pretrained_path}...")
        checkpoint = torch.load(Config.pretrained_path)
        
        # å¤„ç†å¯èƒ½çš„ 'module.' å‰ç¼€ (DataParallel é—ç•™é—®é¢˜)
        new_state_dict = {}
        for k, v in checkpoint.items():
            name = k.replace('module.', '') # åŽ»æŽ‰ module.
            new_state_dict[name] = v
            
        # strict=False å…è®¸å¿½ç•¥ä¸€äº›ä¸åŒ¹é…çš„å±‚ (è™½ç„¶è¿™é‡Œåº”è¯¥å®Œå…¨åŒ¹é…)
        model.load_state_dict(new_state_dict, strict=False)
        print("âœ… Weights loaded successfully! Starting Fine-tuning.")
    else:
        print("âš ï¸ No pretrained path found, training from scratch (NOT RECOMMENDED).")
    
    # 3. æŸå¤±å‡½æ•°ä¸Žä¼˜åŒ–å™¨
    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.lr, weight_decay=1e-5)
    scheduler = CosineAnnealingLR(optimizer, T_max=Config.epochs, eta_min=1e-6)
    
    # æ·±ç›‘ç£æƒé‡ (MedNeXt é»˜è®¤è¾“å‡º 5 ä¸ªå°ºåº¦çš„ç»“æžœ)
    ds_weights = [1.0, 0.5, 0.25, 0.125, 0.0625]
    
    best_dice = 0.0
    
    # 4. è®­ç»ƒå¾ªçŽ¯
    for epoch in range(Config.epochs):
        model.train()
        epoch_loss = 0
        
        with tqdm(train_loader, desc=f"Epoch {epoch+1}/{Config.epochs}") as pbar:
            for batch in pbar:
                inputs, labels = batch["image"].cuda(), batch["label"].cuda()
                
                optimizer.zero_grad()
                outputs = model(inputs) # outputs æ˜¯ä¸€ä¸ªåˆ—è¡¨ (Deep Supervision)
                
                # è®¡ç®—æ·±ç›‘ç£ Loss
                loss = 0
                for i, output in enumerate(outputs):
                    # å¦‚æžœ output å°ºå¯¸å’Œ label ä¸ä¸€è‡´ï¼Œéœ€è¦å¯¹ label è¿›è¡Œä¸‹é‡‡æ ·
                    if output.shape[2:] != labels.shape[2:]:
                        # ç®€å•çš„æœ€è¿‘é‚»ä¸‹é‡‡æ · label
                        labels_ds = torch.nn.functional.interpolate(labels.float(), size=output.shape[2:], mode='nearest').long()
                        loss += ds_weights[i] * loss_function(output, labels_ds)
                    else:
                        loss += ds_weights[i] * loss_function(output, labels)
                
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                pbar.set_postfix({"loss": loss.item()})
    
        scheduler.step()
        if (epoch + 1) % 10 == 0:
             print(f"Epoch {epoch+1} LR: {scheduler.get_last_lr()[0]:.6f}")       

    
        # 5. ç®€å•éªŒè¯ (ä¿å­˜æœ€ä½³æ¨¡åž‹)
        # è¿™é‡Œä¸ºäº†é€Ÿåº¦ï¼Œä»…æ¯ 5 ä¸ª Epoch è·‘ä¸€æ¬¡éªŒè¯
        if (epoch + 1) % 5 == 0:
            current_dice = validate(model, val_loader)
            print(f"Epoch {epoch+1} Val Dice: {current_dice:.4f}")
            
            if current_dice > best_dice:
                best_dice = current_dice
                torch.save(model.state_dict(), os.path.join(Config.save_dir, "best_metric_model.pth"))
        
        # å®šæœŸä¿å­˜
        if (epoch + 1) % 50 == 0:
            torch.save(model.state_dict(), os.path.join(Config.save_dir, f"epoch_{epoch+1}.pth"))



# å®šä¹‰åŽå¤„ç†ï¼šåªä¿ç•™æœ€å¤§çš„è¿žé€šåŸŸ
# applied_labels: è¿™é‡Œå¡«ä½ æƒ³è¦è¿›è¡Œè¿žé€šåŸŸå¤„ç†çš„ç±»åˆ« ID åˆ—è¡¨
# æ¯”å¦‚ 1(å³è‚¾), 2(å·¦è‚¾), 3(è‚è„)... AMOS ä¸­é™¤äº†è¡€ç®¡ç­‰æ•£çŠ¶ç»“æž„ï¼Œå¤§éƒ¨åˆ†å™¨å®˜éƒ½é€‚ç”¨
# è¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œå‡è®¾æ‰€æœ‰å‰æ™¯ç±»åˆ«éƒ½åªä¿ç•™æœ€å¤§è¿žé€šåŸŸ
post_process = KeepLargestConnectedComponent(applied_labels=None, is_onehot=True)

# def validate(model, loader):
#     model.eval()
#     torch.cuda.empty_cache()
#     dice_metric = DiceMetric(include_background=False, reduction="mean")
    
#     with torch.no_grad():
#         for batch in tqdm(loader, desc="Validating"):
#             inputs, labels = batch["image"].cuda(), batch["label"].cuda()
            
#             # -----------------------------------------------------------
#             # ä¿®æ”¹ç‚¹ 1: ä½¿ç”¨æ»‘åŠ¨çª—å£æŽ¨ç† (Sliding Window Inference)
#             # è§£å†³è¾¹ç¼˜çƒ‚çš„é—®é¢˜
#             # -----------------------------------------------------------
#             # roi_size: å¿…é¡»ä¸Žè®­ç»ƒæ—¶çš„ crop_size ä¸€è‡´ (128, 128, 64)
#             # overlap: 0.5 è¡¨ç¤ºçª—å£é‡å ä¸€åŠï¼Œé«˜æ–¯èžåˆæ•ˆæžœæœ€å¥½
#             outputs = sliding_window_inference(
#                 inputs, 
#                 roi_size=(160, 160, 96), 
#                 sw_batch_size=4, 
#                 predictor=model, 
#                 overlap=0.5, 
#                 mode='gaussian'  # å…³é”®ï¼ä½¿ç”¨é«˜æ–¯åŠ æƒå¹³æ»‘è¾¹ç¼˜
#             )
            
#             # MedNeXt æ·±ç›‘ç£æ¨¡å¼ä¸‹å¯èƒ½è¿”å›žåˆ—è¡¨ï¼Œå¤„ç†ä¸€ä¸‹
#             if isinstance(outputs, (list, tuple)):
#                 outputs = outputs[0] # å–æœ€é«˜åˆ†è¾¨çŽ‡è¾“å‡º
            
#             # [B, C, D, H, W] -> Argmax è½¬ä¸ºç±»åˆ«ç´¢å¼• -> One-Hot
#             # æ³¨æ„ï¼šåŽå¤„ç†é€šå¸¸åœ¨ One-Hot æ ¼å¼ä¸Šè¿›è¡Œ
#             outputs_onehot = torch.nn.functional.one_hot(
#                 torch.argmax(outputs, dim=1), 
#                 num_classes=Config.num_classes
#             ).permute(0, 4, 1, 2, 3) # [B, C, D, H, W]
            
#             labels_oh = torch.nn.functional.one_hot(
#                 labels.squeeze(1).long(), 
#                 num_classes=Config.num_classes
#             ).permute(0, 4, 1, 2, 3)

#             # -----------------------------------------------------------
#             # ä¿®æ”¹ç‚¹ 2: æœ€å¤§è¿žé€šåŸŸåŽå¤„ç† (Post Processing)
#             # è§£å†³â€œå¤šé¢„æµ‹å‡ºå‡ ä¸ªå°çš„â€é—®é¢˜
#             # -----------------------------------------------------------
#             # decollate_batch å°† Batch æ‹†å¼€ï¼Œå› ä¸ºåŽå¤„ç†æ˜¯å¯¹å•å¼ å›¾åšçš„
#             outputs_list = decollate_batch(outputs_onehot)
#             outputs_post = []
            
#             for pred in outputs_list:
#                 # å¯¹è¯¥æ ·æœ¬çš„æ‰€æœ‰é€šé“åº”ç”¨â€œä¿ç•™æœ€å¤§è¿žé€šåŸŸâ€
#                 # æ³¨æ„ï¼šè¿™æ­¥è®¡ç®—é‡ç¨å¤§ï¼Œå¦‚æžœå¤ªæ…¢å¯ä»¥åªåœ¨æµ‹è¯•æ—¶ç”¨
#                 try:
#                     pred_pp = post_process(pred)
#                     outputs_post.append(pred_pp)
#                 except Exception as e:
#                     # ä¸‡ä¸€æŠ¥é”™ï¼ˆæ¯”å¦‚å…¨é»‘ï¼‰ï¼Œå°±é€€å›žåŽŸé¢„æµ‹
#                     outputs_post.append(pred)
            
#             # é‡æ–°å †å å›ž Batch
#             outputs_final = torch.stack(outputs_post)
            
#             # è®¡ç®— Dice
#             dice_metric(y_pred=outputs_final, y=labels_oh)
            
#     return dice_metric.aggregate().item()

def validate(model, loader):
    model.eval()
    dice_metric = DiceMetric(...)
    
    with torch.no_grad():
        for batch in tqdm(loader):
            inputs, labels = batch["image"].cuda(), batch["label"].cuda()
            
            # ðŸ”´ æ›¿æ¢ä¸ºå¿«é€ŸæŽ¨ç†
            # æ³¨æ„ï¼šfast_roi_inference è¿”å›žçš„æ˜¯ index (0,1,2...)
            # è€Œ DiceMetric éœ€è¦ One-Hot
            pred_mask = fast_roi_inference(inputs, model, input_size=(96, 160, 160))
            
            # Index -> One-Hot
            outputs_onehot = torch.nn.functional.one_hot(
                pred_mask.squeeze(1).long(), 
                num_classes=Config.num_classes
            ).permute(0, 4, 1, 2, 3)
            
            labels_oh = torch.nn.functional.one_hot(
                labels.squeeze(1).long(), 
                num_classes=Config.num_classes
            ).permute(0, 4, 1, 2, 3)

            dice_metric(y_pred=outputs_onehot, y=labels_oh)
            
    return dice_metric.aggregate().item()


if __name__ == "__main__":
    train()