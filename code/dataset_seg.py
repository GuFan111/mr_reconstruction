# import os
# import glob
# import numpy as np
# import torch
# from torch.utils.data import Dataset
# from monai.transforms import (
#     Compose,
#     RandCropByPosNegLabeld,
#     RandRotate90d,
#     RandFlipd,
#     RandShiftIntensityd,
#     EnsureTyped,
#     ToTensord
# )

# class AMOS_Seg_Dataset(Dataset):
#     def __init__(self, img_root, label_root, split='train', crop_size=(128, 128, 64), cache=False):
#         self.img_root = img_root
#         self.label_root = label_root
#         self.split = split
#         self.crop_size = crop_size
#         self.cache = cache
        
#         # è·å–å…±æœ‰ ID
#         self.img_files = sorted(glob.glob(os.path.join(img_root, '*.npy')))
#         self.data_list = []
        
#         for img_path in self.img_files:
#             name = os.path.basename(img_path)
#             idx = name.split('_')[1].split('.')[0] # amos_0500.npy -> 0500
#             label_name = f"amos_{idx}_label.npy"
#             label_path = os.path.join(label_root, label_name)
            
#             if os.path.exists(label_path):
#                 self.data_list.append({"image": img_path, "label": label_path})
        
#         # ç®€å•åˆ’åˆ† (80% Train, 20% Val)
#         split_idx = int(0.8 * len(self.data_list))
#         if split == 'train':
#             self.data_list = self.data_list[:split_idx]
#         else:
#             self.data_list = self.data_list[split_idx:]
            
#         # å®šä¹‰è®­ç»ƒæ—¶çš„æ•°æ®å¢å¼ºæµæ°´çº¿
#         # æ³¨æ„ï¼šè¿™é‡Œè¾“å…¥å·²ç»æ˜¯ numpy arrayï¼Œä¸éœ€è¦ LoadImage
#         self.train_transforms = Compose([
#             EnsureTyped(keys=["image", "label"]),
#             # 1. éšæœºè£å‰ªï¼šä¿è¯è£å‰ªå—ä¸­åŒ…å«å‰æ™¯ï¼ˆå™¨å®˜ï¼‰
#             RandCropByPosNegLabeld(
#                 keys=["image", "label"],
#                 label_key="label",
#                 spatial_size=crop_size,
#                 pos=2, neg=1, # 2:1 çš„æ¯”ä¾‹é‡‡æ ·å‰æ™¯å’ŒèƒŒæ™¯
#                 num_samples=1,
#                 image_key="image",
#                 image_threshold=0,
#             ),
#             # 2. ç©ºé—´å¢å¼º
#             RandRotate90d(keys=["image", "label"], prob=0.5, spatial_axes=(0, 1)),
#             RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
#             RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
#             RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),
#             # 3. å¼ºåº¦å¢å¼º (ä»…å¯¹ Image)
#             RandShiftIntensityd(keys=["image"], offsets=0.1, prob=0.5),
#         ])

#     def __len__(self):
#         return len(self.data_list)

#     def __getitem__(self, index):
#         item = self.data_list[index]
        
#         # åŠ è½½æ•°æ®
#         img = np.load(item["image"])   # [256, 256, 128]
#         lbl = np.load(item["label"])   # [256, 256, 128]
        
#         # å¢åŠ  Channel ç»´åº¦: [C, D, H, W]
#         img = img[None, ...] 
#         lbl = lbl[None, ...]
        
#         data_dict = {"image": img, "label": lbl}
        
#         if self.split == 'train':
#             # åº”ç”¨å¢å¼ºï¼ŒCrop å‡ºå°å—è¿›è¡Œè®­ç»ƒ (èŠ‚çœæ˜¾å­˜)
#             data_dict = self.train_transforms(data_dict)[0] # MONAI Crop è¿”å›åˆ—è¡¨ï¼Œå–ç¬¬0ä¸ª
#         else:
#             # éªŒè¯é›†ç›´æ¥è½¬ Tensorï¼Œä¸è£å‰ª (æˆ–ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†)
#             data_dict["image"] = torch.from_numpy(data_dict["image"]).float()
#             data_dict["label"] = torch.from_numpy(data_dict["label"]).long()
            
#         return data_dict


import os
import glob
import numpy as np
import torch
from torch.utils.data import Dataset
from monai.transforms import (
    Compose,
    Resized,                  # ğŸŸ¢ æ”¹ä¸º Resized (å¸¦ d)
    RandRotate90d,
    RandFlipd,
    RandShiftIntensityd,
    RandBiasFieldd,          
    NormalizeIntensityd,     
    EnsureTyped,
    ToTensord
)

class AMOS_Seg_Dataset(Dataset):
    def __init__(self, img_root, label_root, split='train', crop_size=(160, 160, 96), cache=False):
        """
        crop_size: åœ¨å¾®è°ƒé˜¶æ®µï¼Œè¿™å®é™…ä¸Šæ˜¯ target_size (ç¼©æ”¾ç›®æ ‡å°ºå¯¸)
        """
        self.img_root = img_root
        self.label_root = label_root
        self.split = split
        self.crop_size = crop_size # e.g. (160, 160, 96)
        
        # è·å–å…±æœ‰ ID
        self.img_files = sorted(glob.glob(os.path.join(img_root, '*.npy')))
        self.data_list = []
        
        for img_path in self.img_files:
            name = os.path.basename(img_path)
            idx = name.split('_')[1].split('.')[0] 
            label_name = f"amos_{idx}_label.npy"
            label_path = os.path.join(label_root, label_name)
            
            if os.path.exists(label_path):
                self.data_list.append({"image": img_path, "label": label_path})
        
        # ç®€å•åˆ’åˆ† (80% Train, 20% Val)
        split_idx = int(0.8 * len(self.data_list))
        if split == 'train':
            self.data_list = self.data_list[:split_idx]
        else:
            self.data_list = self.data_list[split_idx:]
            
        # ====================================================
        # ğŸŸ¢ å¾®è°ƒé˜¶æ®µçš„æ ¸å¿ƒä¿®æ”¹ï¼šå…¨å›¾ Resizeï¼Œä¸å† Crop
        # ====================================================
        self.train_transforms = Compose([
            EnsureTyped(keys=["image", "label"]),
            
            # 1. å¼ºåˆ¶ç¼©æ”¾åˆ°æ¨ç†å°ºå¯¸ (160, 160, 96)
            # image ä½¿ç”¨ trilinear (å¹³æ»‘æ’å€¼)
            # label ä½¿ç”¨ nearest (æœ€è¿‘é‚»ï¼Œä¿è¯æ ‡ç­¾æ˜¯æ•´æ•°)
            Resized(keys=["image"], spatial_size=crop_size, mode="trilinear"),
            Resized(keys=["label"], spatial_size=crop_size, mode="nearest"),
            
            # 2. å¼ºåº¦å½’ä¸€åŒ– (éå¸¸é‡è¦ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ)
            NormalizeIntensityd(keys=["image"], nonzero=True, channel_wise=True),
            RandShiftIntensityd(keys=["image"], offsets=0.1, prob=0.5),
            
            # 3. ç©ºé—´å¢å¼º (åœ¨ Resize ä¹‹ååš)
            RandRotate90d(keys=["image", "label"], prob=0.5, spatial_axes=(0, 1)),
            RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=0),
            RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=1),
            RandFlipd(keys=["image", "label"], prob=0.5, spatial_axis=2),

            ToTensord(keys=["image", "label"]),
        ])

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, index):
        item = self.data_list[index]
        
        # åŠ è½½æ•°æ®
        img = np.load(item["image"])   # [H, W, D]
        lbl = np.load(item["label"])   # [H, W, D]
        
        # å¢åŠ  Channel ç»´åº¦: [C, H, W, D] -> å¯¹åº” [C, X, Y, Z]
        img = img[None, ...] 
        lbl = lbl[None, ...]
        
        data_dict = {"image": img, "label": lbl}
        
        if self.split == 'train':
            # åº”ç”¨ Resize å’Œå¢å¼º
            data_dict = self.train_transforms(data_dict)
            # æ­¤æ—¶è¿”å›çš„æ˜¯ (160, 160, 96) çš„æ•°æ®
        else:
            # éªŒè¯é›†è¿”å›åŸå›¾ï¼Œäº¤ç»™ validate å‡½æ•°é‡Œçš„ fast_inference å»ç¼©æ”¾
            # è¿™æ ·ç®—å‡ºæ¥çš„ Dice æ‰æ˜¯çœŸå®çš„
            data_dict["image"] = torch.from_numpy(data_dict["image"]).float()
            data_dict["label"] = torch.from_numpy(data_dict["label"]).long()
            
        return data_dict