import os
os.environ['OMP_NUM_THREADS'] = '1'
import torch
import torch.nn.functional as F
from torch.optim.lr_scheduler import CosineAnnealingLR
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm
from monai.losses import GeneralizedDiceLoss, DiceCELoss
from monai.metrics import DiceMetric
from monai.utils import set_determinism

# å¯¼å…¥ä½ æ–°å†™çš„ Dataset
from dataset_seg import AMOS_Seg_Dataset
# å¯¼å…¥ MedNeXt å·¥åŽ‚å‡½æ•°
from models.mednext.create_mednext_v1 import create_mednext_v1

# ================= é…ç½® =================
class Config:
    img_root = '/root/autodl-tmp/Proj/data/amos_mri_npy'
    label_root = '/root/autodl-tmp/Proj/data/amos_mri_label_npy'
    save_dir = './logs/mednext_seg_v1_finetune' # ðŸŸ¢ æ”¹ä¸ªåå­—ï¼Œåˆ«è¦†ç›–äº†ä¹‹å‰çš„ Log
    
    # ðŸŸ¢ æŒ‡å‘ä½ ä¹‹å‰ Dice 0.76 çš„æœ€ä½³æ¨¡åž‹
    pretrained_path = './logs/mednext_seg_v1/best_metric_model.pth'
    
    # ðŸŸ¢ å¾®è°ƒå‚æ•°
    batch_size = 2        # å› ä¸ºå…¨å›¾ Resize å˜å°äº†ï¼Œæ˜¾å­˜å¤Ÿç”¨ï¼Œå¯ä»¥åŠ å¤§ BS
    lr = 1e-4             # ðŸŸ¢ é™ä½Žå­¦ä¹ çŽ‡ (ä»Ž 1e-3 é™åˆ° 1e-4)
    epochs = 50           # ðŸŸ¢ åªéœ€è¦è·‘ 30-50 è½®
    
    crop_size = (160, 160, 96) # è¿™æ˜¯ Resize çš„ç›®æ ‡å°ºå¯¸ (X, Y, Z)
    num_classes = 16 

# ================= æžé€ŸæŽ¨ç†å‡½æ•° (åµŒå…¥åœ¨è¿™é‡Œ) =================
def fast_roi_inference(inputs, model, input_size=(160, 160, 96)):
    """
    Validation æ—¶ä½¿ç”¨çš„å¿«é€ŸæŽ¨ç†
    """
    original_size = inputs.shape[2:] 
    
    # 1. é™é‡‡æ ·
    inputs_small = F.interpolate(inputs, size=input_size, mode='area')
    
    # 2. æŽ¨ç†
    with torch.cuda.amp.autocast():
        # model è¾“å‡ºå¯èƒ½æ˜¯ list (æ·±ç›‘ç£)ï¼Œå–ç¬¬ä¸€ä¸ª
        outputs = model(inputs_small)
        if isinstance(outputs, (list, tuple)):
            outputs = outputs[0]
            
    # 3. ä¸Šé‡‡æ · logits (æ¯”ä¸Šé‡‡æ · mask æ›´å¹³æ»‘)
    outputs_large = F.interpolate(outputs, size=original_size, mode='trilinear', align_corners=False)
    
    # 4. ç”Ÿæˆ Mask (Index)
    pred_mask = torch.argmax(outputs_large, dim=1, keepdim=True)
    
    return pred_mask

# ================= éªŒè¯å‡½æ•° (ä½¿ç”¨æžé€Ÿæ¨¡å¼) =================
def validate(model, loader):
    model.eval()
    dice_metric = DiceMetric(include_background=False, reduction="mean")
    
    with torch.no_grad():
        for batch in tqdm(loader, desc="Validating (Fast Mode)"):
            inputs, labels = batch["image"].cuda(), batch["label"].cuda()
            
            # ä½¿ç”¨æžé€ŸæŽ¨ç† (æ¨¡æ‹Ÿéƒ¨ç½²æ—¶çš„çŽ¯å¢ƒ)
            pred_mask = fast_roi_inference(inputs, model, input_size=Config.crop_size)
            
            # è½¬ One-Hot è®¡ç®— Dice
            outputs_onehot = torch.nn.functional.one_hot(
                pred_mask.squeeze(1).long(), 
                num_classes=Config.num_classes
            ).permute(0, 4, 1, 2, 3)
            
            labels_oh = torch.nn.functional.one_hot(
                labels.squeeze(1).long(), 
                num_classes=Config.num_classes
            ).permute(0, 4, 1, 2, 3)

            dice_metric(y_pred=outputs_onehot, y=labels_oh)
            
    return dice_metric.aggregate().item()

# ================= ä¸»è®­ç»ƒé€»è¾‘ =================
def train():
    os.makedirs(Config.save_dir, exist_ok=True)
    set_determinism(seed=0)
    
    # 1. æ•°æ®åŠ è½½
    # train_ds ä¼šè‡ªåŠ¨åš Resizeï¼Œval_ds è¿”å›žåŽŸå›¾
    train_ds = AMOS_Seg_Dataset(Config.img_root, Config.label_root, split='train', crop_size=Config.crop_size)
    val_ds = AMOS_Seg_Dataset(Config.img_root, Config.label_root, split='val')
    
    train_loader = DataLoader(train_ds, batch_size=Config.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)
    
    print(f"Training on resized images: {Config.crop_size}")
    
    # 2. æ¨¡åž‹åˆå§‹åŒ–
    model = create_mednext_v1(
        num_input_channels=1,
        num_classes=Config.num_classes,
        model_id='S',
        kernel_size=3,
        deep_supervision=True
    ).cuda()

    # 3. åŠ è½½é¢„è®­ç»ƒæƒé‡ (å…³é”®)
    if Config.pretrained_path and os.path.exists(Config.pretrained_path):
        print(f"ðŸ”„ Loading pretrained weights from {Config.pretrained_path}...")
        checkpoint = torch.load(Config.pretrained_path)
        new_state_dict = {k.replace('module.', ''): v for k, v in checkpoint.items()}
        model.load_state_dict(new_state_dict, strict=False)
        print("âœ… Weights loaded! Starting Low-Res Fine-tuning.")
    else:
        print("âŒ ERROR: No pretrained weights found! Fine-tuning requires a base model.")
        return
    
    # 4. ä¼˜åŒ–å™¨ä¸Ž Loss
    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
    optimizer = torch.optim.AdamW(model.parameters(), lr=Config.lr, weight_decay=1e-5)
    scheduler = CosineAnnealingLR(optimizer, T_max=Config.epochs, eta_min=1e-6)
    
    # æ·±ç›‘ç£æƒé‡
    ds_weights = [1.0, 0.5, 0.25, 0.125, 0.0625]
    best_dice = 0.0
    
    # 5. è®­ç»ƒå¾ªçŽ¯
    for epoch in range(Config.epochs):
        model.train()
        epoch_loss = 0
        
        with tqdm(train_loader, desc=f"Epoch {epoch+1}/{Config.epochs}") as pbar:
            for batch in pbar:
                inputs, labels = batch["image"].cuda(), batch["label"].cuda()
                
                optimizer.zero_grad()
                
                # å¼€å¯æ··åˆç²¾åº¦è®­ç»ƒ (åŠ é€Ÿ + çœæ˜¾å­˜)
                with torch.cuda.amp.autocast():
                    outputs = model(inputs) # outputs list
                    
                    loss = 0
                    for i, output in enumerate(outputs):
                        # ðŸŸ¢ ä¿®å¤æ ¸å¿ƒï¼šå¦‚æžœ output å°ºå¯¸å˜å°äº†ï¼Œå°±æŠŠ label ä¹Ÿå˜å°
                        if output.shape[2:] != labels.shape[2:]:
                            # ä½¿ç”¨ nearest æ’å€¼ä¿æŒæ ‡ç­¾ä¸ºæ•´æ•°
                            labels_ds = torch.nn.functional.interpolate(
                                labels.float(), 
                                size=output.shape[2:], 
                                mode='nearest'
                            ).long()
                            loss += ds_weights[i] * loss_function(output, labels_ds)
                        else:
                            # å°ºå¯¸ä¸€è‡´ç›´æŽ¥è®¡ç®—
                            loss += ds_weights[i] * loss_function(output, labels)
                
                # è¿™é‡Œçš„ scaler éœ€è¦åœ¨å¤–éƒ¨å®šä¹‰ï¼Œç®€å•èµ·è§ç›´æŽ¥ backward
                # å¦‚æžœæ˜¾å­˜ä¸å¤Ÿï¼Œå»ºè®®åŠ ä¸Š GradScaler
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                pbar.set_postfix({"loss": loss.item()})
    
        scheduler.step()
        
        # æ¯ 2 ä¸ª Epoch éªŒè¯ä¸€æ¬¡ (å› ä¸ºå¾®è°ƒå¾ˆå¿«)
        if (epoch + 1) % 2 == 0:
            # è¿™é‡Œçš„ validate ç”¨çš„æ˜¯ fast_roi_inference
            current_dice = validate(model, val_loader)
            print(f"Epoch {epoch+1} Fast Val Dice: {current_dice:.4f}")
            
            if current_dice > best_dice:
                best_dice = current_dice
                torch.save(model.state_dict(), os.path.join(Config.save_dir, "best_finetuned_model.pth"))
                print("ðŸ’¾ Best model saved!")

if __name__ == "__main__":
    train()