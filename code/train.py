# train.py

import os
import sys
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

import time
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader
import torch.nn.functional as F
from tqdm import tqdm
import logging

from dataset import AMOS_Dataset
from models.model import DIF_Net
from utils import convert_cuda, save_visualization_3view, simple_eval, gpu_slice_volume, GPUDailyScanSimulator, ElasticDeformation, simple_eval_metric, compute_gradient



# ==========================================
#  é…ç½®åŒºåŸŸ
# ==========================================
class Config:
    name = 'dif_amos_roi_v2' # å»ºè®®æ”¹åä»¥åŒºåˆ†æ—§å®éªŒ
    # æŒ‡å‘ä½ åˆšæ‰é¢„å¤„ç†åçš„æ•°æ®ç›˜è·¯å¾„
    data_root = r'/root/autodl-tmp/Proj/data/amos_mri_npy'
    label_root = r'/root/autodl-tmp/Proj/data/amos_mri_label_npy'
    # resume_path = r'/root/autodl-tmp/Proj/code/logs/dif_amos_roi_v2/ep_100.pth'
    resume_path = None
    gpu_id = 0
    num_workers = 22 # é…åˆæ•°æ®ç›˜è¯»å–ï¼Œä¸éœ€è¦è®¾ç½®è¿‡å¤§
    preload = False # å¦‚æœå†…å­˜ä¸å¤Ÿï¼ˆç³»ç»Ÿç›˜çˆ†è¿‡ï¼‰ï¼Œå»ºè®®è®¾ä¸º False
    batch_size = 1
    epoch = 400
    lr = 5e-4
    num_views = 3
    out_res = (256, 256, 128)
    num_points = 100000 # é…åˆ ROI é‡‡æ ·ï¼Œ10w ç‚¹å°±èƒ½è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœ
    combine = 'attention'
    eval_freq = 10
    save_freq = 50
    gamma = 0.95
    sigma = (0.02, 0.02, 0.08)
    # sigma = (0.0, 0.0, 0.0)



def worker_init_fn(worker_id):
    np.random.seed((worker_id + torch.initial_seed()) % np.iinfo(np.int32).max)

def setup_logger(log_file):
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    # æ–‡ä»¶è¾“å‡º
    fh = logging.FileHandler(log_file, mode='a')
    fh.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
    logger.addHandler(fh)

    # æ§åˆ¶å°è¾“å‡º
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter('%(message)s'))
    logger.addHandler(ch)

    return logger

if __name__ == '__main__':
    os.environ['CUDA_VISIBLE_DEVICES'] = str(Config.gpu_id)
    save_dir = f'./logs/{Config.name}'
    os.makedirs(save_dir, exist_ok=True)

    logger = setup_logger(os.path.join(save_dir, 'train_log.txt'))
    logger.info(f"Start training: {Config.name}")
    logger.info(f"Config: Batch={Config.batch_size}, LR={Config.lr}, Sigma={Config.sigma}")

    train_dst = AMOS_Dataset(
        data_root=Config.data_root,
        label_root=Config.label_root,
        split='train',
        npoint=Config.num_points,
        out_res=Config.out_res
    )
    # å¦‚æœ preload=Falseï¼Œå»ºè®®è®¾ç½® num_workers å¼€å¯å¤šçº¿ç¨‹è¯»å–
    train_loader = DataLoader(
        train_dst,
        batch_size=Config.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        worker_init_fn=worker_init_fn
    )

    val_dst = AMOS_Dataset(
        data_root=Config.data_root,
        label_root=Config.label_root,
        split='eval',
        npoint=50000, # è¯„ä¼°æ—¶é‡‡æ ·ç‚¹å¯ä»¥å°‘ä¸€ç‚¹
        out_res=Config.out_res
    )

    eval_loader = DataLoader(val_dst, batch_size=1, shuffle=False)

    # 1. å®ä¾‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    model = DIF_Net(num_views=Config.num_views, combine=Config.combine).cuda()
    optimizer = torch.optim.Adam(model.parameters(), lr=Config.lr, weight_decay=0)
    for group in optimizer.param_groups:
        group.setdefault('initial_lr', Config.lr)

    # 2. ğŸŸ¢ è§£ææ–­ç‚¹ç»­è®­ (ä¼˜å…ˆäºè°ƒåº¦å™¨åˆå§‹åŒ–)
    start_epoch = 0
    if hasattr(Config, 'resume_path') and Config.resume_path and os.path.exists(Config.resume_path):
        logger.info(f"==> [Resume] å‘ç°é¢„è®­ç»ƒæƒé‡ï¼Œæ­£åœ¨åŠ è½½: {Config.resume_path}")
        checkpoint = torch.load(Config.resume_path, map_location='cuda')
        model.load_state_dict(checkpoint)

        try:
            base_name = os.path.basename(Config.resume_path)
            start_epoch = int(base_name.split('_')[1].split('.')[0]) + 1
            logger.info(f"==> [Resume] è§£æåˆ°åŸºç¡€è½®æ¬¡ï¼Œå°†ä» Epoch {start_epoch} å¼€å§‹è®­ç»ƒã€‚")
        except Exception as e:
            logger.warning(f"==> [Resume] æ— æ³•ä»æ–‡ä»¶åè§£æ Epochï¼Œé»˜è®¤ä» Epoch 0 é‡æ–°è®¡æ•°ã€‚é”™è¯¯: {e}")

    # 3. ğŸŸ¢ ä¼˜é›…åˆå§‹åŒ–è°ƒåº¦å™¨ (æ¶ˆé™¤ UserWarning)
    # ç›´æ¥ä¼ å…¥ last_epoch=start_epoch-1ï¼Œè®© PyTorch è‡ªå·±ç®—å¥½å½“å‰åº”è¯¥å¤„äºä»€ä¹ˆå­¦ä¹ ç‡
    lr_scheduler = torch.optim.lr_scheduler.StepLR(
        optimizer, step_size=20, gamma=Config.gamma, last_epoch=start_epoch - 1
    )

    # 4. ğŸŸ¢ è¡¥å›ä¸¢å¤±çš„å½¢å˜å™¨ä¸æ¨¡æ‹Ÿå™¨ (æ¶ˆé™¤ NameError)
    train_simulator = GPUDailyScanSimulator(noise_level=0.0, blur_sigma=0.0).cuda()
    eval_simulator = GPUDailyScanSimulator(noise_level=0.0, blur_sigma=0.0).cuda()
    deformer = ElasticDeformation(grid_size=8, sigma=Config.sigma).cuda()

    logger.info("Start Training Loop...")
    epoch = start_epoch

    while epoch <= Config.epoch:
        loss_list = []
        model.train()

        with tqdm(train_loader, desc=f'Epoch {epoch}/{Config.epoch}', ncols=120, unit='img') as pbar:
            for item in pbar:
                optimizer.zero_grad()
                item = convert_cuda(item)

                with torch.no_grad():
                    prior_vol = item['image']
                    prior_mask = (item['mask'] == 6).float() # ğŸŸ¢ æŠŠ Mask å–å‡ºæ¥

                    # 1. è®©å›¾åƒå’Œ Mask åŒæ­¥å‘ç”Ÿç‰©ç†å½¢å˜
                    combined_vol = torch.cat([prior_vol, prior_mask], dim=1)
                    warped_combined = deformer(combined_vol, mode='bilinear')

                    target_vol = warped_combined[:, 0:1]
                    target_mask = warped_combined[:, 1:2] # ğŸŸ¢ è·å–å½¢å˜åçš„çœŸå®å™¨å®˜ä½ç½®

                    # 2. ä» Target ä¸­åˆ‡ç‰‡å¹¶æ›´æ–°è¾“å…¥
                    item['projs'] = gpu_slice_volume(target_vol)
                    item['prior'] = prior_vol

                    # 3. åŠ¨æ€é‡æ–°é‡‡æ · GT å’Œ GT_Mask
                    uv = item['points']
                    uv_sampling = uv[..., [2, 1, 0]].reshape(uv.shape[0], 1, 1, uv.shape[1], 3)

                    # åŒæ—¶é‡‡æ ·åƒç´ å€¼å’Œæ©ç å€¼
                    gt = F.grid_sample(target_vol, uv_sampling, align_corners=True)[:, :, 0, 0, :]
                    gt_mask_sampled = F.grid_sample(target_mask, uv_sampling, align_corners=True)[:, :, 0, 0, :]
                    item['p_gt'] = gt

                # ==========================================
                # ğŸŸ¢ é˜¶æ®µ 3: çº¯ç²¹é¶åŒº Loss å¼•æ“ (æš´åŠ›èšç„¦ç‰ˆ)
                # ==========================================
                pred_val, delta_coords = model(item)

                # 1. è®¡ç®—åŸºç¡€ L1 è¯¯å·®
                # æ­¤æ—¶æ‰€æœ‰çš„ 10 ä¸‡ä¸ªé‡‡æ ·ç‚¹ï¼Œå·²ç»åœ¨ dataset å±‚é¢è¢«ç‰©ç†é”æ­»åœ¨äº†è†¨èƒ€é¶åŒºå†…
                # ç›´æ¥æ±‚å‡å€¼ï¼Œä¸éœ€è¦ä»»ä½•ç©ºé—´æƒé‡ï¼Œä¿è¯è‚è„ä¸ç¼“å†²å¸¦æ¢¯åº¦çš„å¹³æ»‘è¿‡æ¸¡
                loss_recon = F.l1_loss(pred_val, gt, reduction='mean')

                # 2. è½»å¾®çš„ä½ç§»æ­£åˆ™ (é˜²æ­¢è¾¹ç¼˜ç¼“å†²å¸¦çš„å½¢å˜åœºå‘æ•£)
                loss_reg = torch.mean(delta_coords ** 2)

                # 3. æ€» Loss
                w_reg = 0.02
                loss = loss_recon + w_reg * loss_reg

                loss_list.append(loss.item())
                loss.backward()
                # ==========================================

                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()

                current_lr = optimizer.param_groups[0]["lr"]
                pbar.set_postfix({'loss': f'{np.mean(loss_list):.6f}', 'lr': f'{current_lr:.6f}'})

        logger.info(f"Epoch {epoch} | Train Loss: {np.mean(loss_list):.6f} | LR: {current_lr:.2e}")


        if epoch > 0 and epoch % Config.save_freq == 0:
            torch.save(model.state_dict(), os.path.join(save_dir, f'ep_{epoch}.pth'))

        if epoch == 0 or epoch % Config.eval_freq == 0:
            print(f" --> Running Evaluation at Epoch {epoch}...")

            eval_start_time = time.time()

            save_visualization_3view(
                model, val_dst, epoch,
                save_dir=os.path.join(save_dir, 'vis'),
                simulator=eval_simulator,
                prior_deformer=deformer  # ä¼ å…¥ä¿®æ”¹åçš„å½¢å˜å™¨
            )

            model.eval()
            psnrs, ssims = [], []
            inference_times = []

            with torch.no_grad():
                for i, v_item in enumerate(eval_loader):
                    if i >= 5: break
                    v_item = convert_cuda(v_item)

                    prior_vol = v_item['image']

                    # ğŸŸ¢ 1. è®°å½•å½“å‰ç‹‚é‡çš„éšæœºå®‡å®™çŠ¶æ€ï¼ˆä¿æŠ¤è®­ç»ƒçš„éšæœºæ€§ï¼‰
                    cpu_rng_state = torch.get_rng_state()
                    gpu_rng_state = torch.cuda.get_rng_state()

                    # ğŸŸ¢ 2. æ—¶é—´é™æ­¢ï¼šä¸ºå½“å‰æ ·æœ¬æ³¨å…¥ç»å¯¹å›ºå®šçš„å‘½è¿ (Seed)
                    # ä¿è¯ amos_507 æ¯æ¬¡ eval é­é‡çš„å½¢å˜åœºè¿å°æ•°ç‚¹å 6 ä½éƒ½ä¸€æ¨¡ä¸€æ ·ï¼
                    fixed_seed = 2026 + i
                    torch.manual_seed(fixed_seed)
                    torch.cuda.manual_seed(fixed_seed)

                    # ğŸŸ¢ 3. å®¿å‘½å½¢å˜ï¼šç”Ÿæˆæ°¸è¿œä¸€è‡´çš„ Target
                    if 'mask' in v_item: # å¦‚æœä½ ç”¨äº† BBox è¯„æµ‹ï¼ŒæŠŠ mask ä¹Ÿå¸¦ä¸Š
                        prior_mask = (v_item['mask'] == 6).float()
                        combined_eval = torch.cat([prior_vol, prior_mask], dim=1)
                        warped_eval = deformer(combined_eval, mode='bilinear')
                        target_vol = warped_eval[:, 0:1]
                        target_mask = warped_eval[:, 1:2]
                    else:
                        target_vol = deformer(prior_vol, mode='bilinear')
                        target_mask = None # è§†ä½ å½“å‰ç”¨çš„å“ªç§ eval é€»è¾‘è€Œå®š

                    # ğŸŸ¢ 4. æ¢å¤æ—¶é—´çš„æµåŠ¨ï¼šæŠŠéšæœºçŠ¶æ€è¿˜ç»™ç³»ç»Ÿ
                    torch.set_rng_state(cpu_rng_state)
                    torch.cuda.set_rng_state(gpu_rng_state)

                    # --- åç»­çš„åˆ‡ç‰‡ã€æ¨¡å‹æ¨ç†ã€PSNR/SSIM è®¡ç®—å®Œå…¨ä¿æŒä¸å˜ ---
                    v_item['projs'] = gpu_slice_volume(target_vol)
                    v_item['prior'] = prior_vol

                    torch.cuda.synchronize()
                    t_start = time.time()

                    pred, _ = model(v_item, is_eval=True, eval_npoint=50000)

                    torch.cuda.synchronize()
                    t_end = time.time()
                    inference_times.append(t_end - t_start)

                    # ==========================================
                    # ğŸŸ¢ æ•°æ®è§£æ„ä¸ç»ˆææµ‹è°
                    # ==========================================
                    pred_np = pred[0, 0].cpu().numpy().reshape(v_item['image'].shape[2:])
                    gt_img_np = target_vol.cpu().numpy()[0, 0]

                    # ğŸ”´ ä¿®å¤ Bug 1ï¼šå¿…é¡»ä½¿ç”¨å½¢å˜åçš„ target_mask æ¥å®šä½ï¼
                    gt_mask_np = (target_mask.cpu().numpy()[0, 0] > 0.5).astype(np.float32)

                    # æå–è‚è„çš„ 3D ç‰©ç†è¾¹ç•Œæ¡† (BBox)
                    coords = np.argwhere(gt_mask_np > 0.5)
                    if len(coords) > 0:
                        x_min, y_min, z_min = coords.min(axis=0)
                        x_max, y_max, z_max = coords.max(axis=0)

                        # ä¸ºäº†ç»™ SSIM æ»‘åŠ¨çª—å£ç•™ä¸‹ä¸€ç‚¹è®¡ç®—ç©ºé—´ï¼Œå¹¶æ£€éªŒç½‘ç»œå¯¹è¾¹ç•Œè„‚è‚ªçš„æ‹Ÿåˆ
                        # æˆ‘ä»¬åŠ ä¸Š 10 ä¸ªä½“ç´ çš„è¯„ä¼° Marginï¼ˆä¸è¶…è¿‡è®­ç»ƒæ—¶çš„ 15ï¼‰
                        margin = 10
                        x_min = max(0, x_min - margin)
                        y_min = max(0, y_min - margin)
                        z_min = max(0, z_min - margin)
                        x_max = min(gt_img_np.shape[0]-1, x_max + margin)
                        y_max = min(gt_img_np.shape[1]-1, y_max + margin)
                        z_max = min(gt_img_np.shape[2]-1, z_max + margin)

                        # å¼ºè¡Œè£åˆ‡å‡ºåŒ…å«å™¨å®˜å’Œæå…¶å¾®å°ç¼“å†²å¸¦çš„å¹²å‡€é•¿æ–¹ä½“ï¼
                        gt_roi = gt_img_np[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]
                        pred_roi = pred_np[x_min:x_max+1, y_min:y_max+1, z_min:z_max+1]

                        # ğŸ”´ é¿å¼€é™·é˜± 2ï¼šç»å¯¹ä¸ä¹˜ mask_roiï¼ç›´æ¥è¯„ä¼°è¿™ä¸ªâ€œå¸¦è‚‰â€çš„é•¿æ–¹ä½“ï¼
                        p, s = simple_eval_metric(gt_roi, pred_roi)
                        psnrs.append(p)
                        ssims.append(s)
                    else:
                        print(f"  [Warning] {v_item['name'][0]} æå– BBox å¤±è´¥ã€‚")


            avg_psnr = np.mean(psnrs)
            avg_ssim = np.mean(ssims)
            avg_time = np.mean(inference_times)
            eval_msg = f" Â  Â  [Eval Result] Epoch {epoch}: PSNR = {avg_psnr:.4f} | SSIM = {avg_ssim:.4f}"
            print(f"Inference Time = {avg_time:.4f}s")
            logger.info(eval_msg)

        lr_scheduler.step()
        epoch += 1