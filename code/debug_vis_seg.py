import os
os.environ['OMP_NUM_THREADS'] = '1'
import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from dataset_seg import AMOS_Seg_Dataset
from models.mednext.create_mednext_v1 import create_mednext_v1

# --- æ–°å¢å¼•ç”¨ ---
from monai.inferers import sliding_window_inference
from monai.transforms import KeepLargestConnectedComponent
from monai.data import decollate_batch

import scipy.ndimage as ndimage

# ================= é…ç½®åŒºåŸŸ =================
class Config:
    img_root = '/root/autodl-tmp/Proj/data/amos_mri_npy'
    label_root = '/root/autodl-tmp/Proj/data/amos_mri_label_npy'
    
    # å¡«å…¥ä½ è®­ç»ƒå¥½çš„æœ€ä½³æ¨¡å‹è·¯å¾„
    checkpoint_path = './logs/mednext_seg_v1/best_metric_model.pth' 
    
    num_classes = 16
    crop_size = (160, 160, 96) # å¿…é¡»ä¸è®­ç»ƒæ—¶çš„ patch size ä¸€è‡´

def show_slices(img_np, gt_np, pred_np=None, save_name='debug_vis_fixed.png'):
    """
    ä¿®æ­£åçš„å¯è§†åŒ–ï¼šæ­£ç¡®å¯¹åº” Axial, Coronal, Sagittal
    è¾“å…¥å½¢çŠ¶: [X, Y, Z] (RAS)
    """
    w, h, d = img_np.shape
    sx, sy, sz = w//2, h//2, d//2
    
    # --- ä¿®æ­£åˆ‡ç‰‡é€»è¾‘ä¸æ—‹è½¬ ---
    # 1. Axial (è½´çŠ¶é¢): åˆ‡ Z è½´ï¼Œçœ‹ XY å¹³é¢ã€‚
    #    é€šå¸¸éœ€è¦æ—‹è½¬ 90 åº¦æ‰èƒ½æ­£è¿‡æ¥ (Anterioråœ¨ä¸Š, Rightåœ¨å·¦)
    slice_ax_img = np.rot90(img_np[:, :, sz]) 
    slice_ax_gt  = np.rot90(gt_np[:, :, sz])
    
    # 2. Coronal (å† çŠ¶é¢): åˆ‡ Y è½´ï¼Œçœ‹ XZ å¹³é¢ã€‚
    #    é€šå¸¸ä¹Ÿéœ€è¦æ—‹è½¬ 90 åº¦ (Superioråœ¨ä¸Š)
    slice_co_img = np.rot90(img_np[:, sy, :])
    slice_co_gt  = np.rot90(gt_np[:, sy, :])
    
    # 3. Sagittal (çŸ¢çŠ¶é¢): åˆ‡ X è½´ï¼Œçœ‹ YZ å¹³é¢ã€‚
    #    é€šå¸¸ä¹Ÿéœ€è¦æ—‹è½¬ 90 åº¦ (Superioråœ¨ä¸Š)
    slice_sa_img = np.rot90(img_np[sx, :, :])
    slice_sa_gt  = np.rot90(gt_np[sx, :, :])

    slices_img = [slice_ax_img, slice_co_img, slice_sa_img]
    slices_gt  = [slice_ax_gt,  slice_co_gt,  slice_sa_gt]
    
    if pred_np is not None:
        slice_ax_pred = np.rot90(pred_np[:, :, sz])
        slice_co_pred = np.rot90(pred_np[:, sy, :])
        slice_sa_pred = np.rot90(pred_np[sx, :, :])
        slices_pred = [slice_ax_pred, slice_co_pred, slice_sa_pred]
    
    # ç»˜å›¾é…ç½®
    rows = 3 if pred_np is not None else 2
    cols = 3
    fig, axes = plt.subplots(rows, cols, figsize=(12, 4 * rows))
    
    titles = ['Axial (XY)', 'Coronal (XZ)', 'Sagittal (YZ)']
    
    for i in range(3):
        # 1. Image
        ax = axes[0, i]
        ax.imshow(slices_img[i], cmap='gray')
        ax.set_title(f"{titles[i]} - Image", fontsize=12)
        ax.axis('off')
        
        # 2. GT Overlay
        ax = axes[1, i]
        ax.imshow(slices_img[i], cmap='gray', alpha=0.6)
        masked_gt = np.ma.masked_where(slices_gt[i] == 0, slices_gt[i])
        ax.imshow(masked_gt, cmap='tab20', alpha=0.7, vmin=0, vmax=15)
        ax.set_title(f"{titles[i]} - Ground Truth", fontsize=12)
        ax.axis('off')

        # 3. Prediction Overlay
        if pred_np is not None:
            ax = axes[2, i]
            ax.imshow(slices_img[i], cmap='gray', alpha=0.6)
            masked_pred = np.ma.masked_where(slices_pred[i] == 0, slices_pred[i])
            ax.imshow(masked_pred, cmap='tab20', alpha=0.7, vmin=0, vmax=15)
            ax.set_title(f"{titles[i]} - Prediction", fontsize=12)
            ax.axis('off')

    plt.tight_layout()
    plt.savefig(save_name)
    print(f"Saved visualization to {save_name}")
    plt.close()


def post_process_gap_closing(pred_numpy, kernel_size=3):
    """
    é’ˆå¯¹â€œæ–­è£‚â€é—®é¢˜çš„å½¢æ€å­¦ä¿®å¤
    """
    # ç»“æœå®¹å™¨
    result = np.zeros_like(pred_numpy)
    
    # ğŸŸ¢ ä¿®å¤æ ¸å¿ƒï¼šè‡ªåŠ¨è·å–è¾“å…¥æ•°æ®çš„ç»´åº¦ (ndim)
    # å¦‚æœè¾“å…¥æ˜¯ [D, H, W]ï¼Œndim=3ï¼›å¦‚æœå¤šäº†ä¸ª batch ç»´åº¦ [1, D, H, W]ï¼Œndim=4
    ndim = pred_numpy.ndim 
    
    # ğŸŸ¢ åŠ¨æ€ç”Ÿæˆç»“æ„å…ƒç´ ï¼Œä¿è¯ç»´åº¦æ°¸è¿œåŒ¹é…
    struct = ndimage.generate_binary_structure(ndim, 1) 
    
    # è·å–å›¾ä¸­å‡ºç°çš„æ‰€æœ‰ç±»åˆ« (è·³è¿‡èƒŒæ™¯ 0)
    classes = np.unique(pred_numpy)
    classes = classes[classes != 0]
    
    if len(classes) == 0:
        return pred_numpy
        
    for c in classes:
        # 1. æå–å½“å‰å™¨å®˜çš„äºŒå€¼ Mask
        binary_mask = (pred_numpy == c)
        
        # 2. æ‰§è¡Œé—­è¿ç®—
        try:
            closed_mask = ndimage.binary_closing(binary_mask, structure=struct, iterations=1)
            result[closed_mask] = c
        except RuntimeError as e:
            print(f"âš ï¸ Morphology error for class {c}: {e}")
            result[binary_mask] = c # å‡ºé”™å°±ä¿æŒåŸæ ·
            
    return result

def fast_roi_inference(inputs, model, input_size=(160, 160, 96)):
    """
    è¾“å…¥: [B, C, D, H, W] åŸå§‹å¤§å›¾
    è¾“å‡º: [B, C, D, H, W] åŸå§‹å°ºå¯¸çš„ Mask
    """
    # 1. è®°å½•åŸå§‹å°ºå¯¸
    original_size = inputs.shape[2:] 
    
    # 2. æé€Ÿé™é‡‡æ · (Downsample)
    # mode='area' æˆ– 'trilinear' é€Ÿåº¦å¾ˆå¿«
    # input_size è¶Šå°è¶Šå¿«ï¼Œå»ºè®®å°è¯• (64, 128, 128) ç”šè‡³ (48, 96, 96)
    inputs_small = F.interpolate(inputs, size=input_size, mode='area')
    
    # 3. å¼€å¯åŠç²¾åº¦ (FP16) åŠ é€Ÿæ¨ç†
    with torch.cuda.amp.autocast():
        with torch.no_grad():
            outputs_small = model(inputs_small)
            
    # 4. æé€Ÿä¸Šé‡‡æ · (Upsample) å›åŸå°ºå¯¸
    # æ­¤æ—¶ä¸éœ€è¦ softmaxï¼Œç›´æ¥æ’å€¼ logits ç”šè‡³æ›´å¿«
    outputs_large = F.interpolate(outputs_small, size=original_size, mode='trilinear', align_corners=False)
    
    # 5. äºŒå€¼åŒ– (åœ¨ GPU ä¸Šå®Œæˆï¼Œä¸è¦è½¬ CPU!)
    pred_mask = torch.argmax(outputs_large, dim=1, keepdim=True)
    
    return pred_mask

# ================= ä¸»é€»è¾‘ =================
def main():
    # å®šä¹‰åå¤„ç†ï¼šä¿ç•™æœ€å¤§è¿é€šåŸŸ (è§£å†³"å¤šé¢„æµ‹å‡ ä¸ªå°çš„"é—®é¢˜)
    # æ³¨æ„ï¼špost_process éœ€è¦ä½œç”¨åœ¨ One-Hot æ ¼å¼æˆ–è€…æ˜¯ [C, D, H, W] æ ¼å¼ä¸Š
    post_process = KeepLargestConnectedComponent(applied_labels=None, is_onehot=True)

    val_ds = AMOS_Seg_Dataset(Config.img_root, Config.label_root, split='val')
    # å»ºè®®åŠ ä¸Š target_id è¿‡æ»¤ï¼Œå›ºå®šçœ‹æŸä¸€ä¸ªç—…äººï¼Œæ–¹ä¾¿å¯¹æ¯”
    # val_ds.data_list = [item for item in val_ds.data_list if "0507" in item['image']] 
    
    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False) # Debug æ—¶å»ºè®® shuffle=False
    
    print(">>> Loading one sample from validation set...")
    batch = next(iter(val_loader))
    image = batch['image'] 
    label = batch['label'] 
    
    # ---------------- æ¨ç†æ ¸å¿ƒä¿®æ”¹åŒºåŸŸ ----------------
    pred_np = None # åˆå§‹åŒ–ä¸º None
    
    if Config.checkpoint_path and os.path.exists(Config.checkpoint_path):
        print(f">>> Loading model from {Config.checkpoint_path}...")
        model = create_mednext_v1(
            num_input_channels=1,
            num_classes=Config.num_classes,
            model_id='S',
            kernel_size=3,
            deep_supervision=False 
        ).cuda()
        
        # åŠ è½½æƒé‡
        state_dict = torch.load(Config.checkpoint_path)
        new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict, strict=False)
        model.eval()
        
        print(">>> Running Sliding Window Inference & Post-Processing...")
        with torch.no_grad():
            img_cuda = image.cuda()
            
            # # --- 1. æ»‘åŠ¨çª—å£æ¨ç† ---
            # outputs = sliding_window_inference(
            #     img_cuda, 
            #     roi_size=Config.crop_size, 
            #     sw_batch_size=4, 
            #     predictor=model, 
            #     overlap=0.5, 
            #     mode='gaussian' 
            # )
            
            # if isinstance(outputs, (list, tuple)): outputs = outputs[0]

            # # --- 2. å‡†å¤‡åå¤„ç†æ•°æ® ---
            # # è½¬ One-Hot: [B, num_classes, D, H, W]
            # pred_idx = torch.argmax(outputs, dim=1, keepdim=True)
            # pred_onehot = torch.nn.functional.one_hot(pred_idx.squeeze(1), Config.num_classes).permute(0, 4, 1, 2, 3)
            
            # # --- 3. æœ€å¤§è¿é€šåŸŸåå¤„ç† (MONAI) ---
            # # è§£å†³å‡é˜³æ€§å°å—
            # pred_post_list = decollate_batch(pred_onehot)
            # pred_post_processed = post_process(pred_post_list[0])
            
            # # --- 4. è½¬å›ç´¢å¼•å¹¶è½¬ä¸º Numpy ---
            # # [C, D, H, W] -> argmax -> [D, H, W] (Tensor)
            # pred_final_tensor = torch.argmax(pred_post_processed, dim=0)
            
            # # ğŸŸ¢ å…³é”®ä¿®æ­£æ­¥éª¤ï¼šå…ˆè½¬ CPU Numpyï¼Œèµ‹å€¼ç»™ pred_np
            # pred_np = pred_final_tensor.cpu().numpy()
            
            # # --- 5. å½¢æ€å­¦é—­è¿ç®— (Custom) ---
            # # è§£å†³"æ–­è£‚"é—®é¢˜ã€‚æ­¤æ—¶ pred_np å·²ç»æ˜¯ Numpy æ•°ç»„äº†ï¼Œä¸ä¼šæŠ¥é”™
            # pred_np = post_process_gap_closing(pred_np, kernel_size=3)

            # æ³¨æ„ï¼šfast_roi_inference è¿”å›çš„å°±æ˜¯ [B, 1, D, H, W] çš„ mask ç´¢å¼•
            pred_mask_tensor = fast_roi_inference(img_cuda, model, input_size=(160, 160, 96))
            
            # å› ä¸ºå‡½æ•°å†…éƒ¨å·²ç»åšè¿‡ argmax äº†ï¼Œæ‰€ä»¥è¿™é‡Œç›´æ¥è½¬ numpy å³å¯
            # [B, 1, D, H, W] -> [D, H, W]
            pred_np = pred_mask_tensor[0, 0].cpu().numpy()

    # ---------------- å¯è§†åŒ– ----------------
    # åªæœ‰å½“ pred_np æˆåŠŸç”Ÿæˆæ—¶æ‰ç”»å›¾ï¼Œé¿å… None æŠ¥é”™
    if pred_np is not None:
        img_np = image[0, 0].numpy()
        gt_np = label[0, 0].numpy()
        show_slices(img_np, gt_np, pred_np, save_name='debug_vis_optimized.png')
    else:
        print("âŒ Model inference failed or checkpoint not found.")

if __name__ == '__main__':
    main()