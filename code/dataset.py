# dataset.py

import os
import json
import glob
import numpy as np
from torch.utils.data import Dataset
from copy import deepcopy
from tqdm import tqdm


class OrthogonalGeometry(object):
    def project(self, points, view_idx):
        p = deepcopy(points)
        # å¯¹åº”ï¼š0-Axial(XY), 1-Coronal(XZ), 2-Sagittal(YZ)
        if view_idx == 0:   uv = p[:, [0, 1]]
        elif view_idx == 1: uv = p[:, [0, 2]]
        elif view_idx == 2: uv = p[:, [1, 2]]
        return uv

class AMOS_Dataset(Dataset):
    def __init__(self, data_root, label_root, split='train', npoint=5000, out_res=(256, 256, 128), preload=False):
        super().__init__()
        self.data_root = data_root
        self.label_root = label_root # ä½ éœ€è¦è¿™ä¸ªç›®å½•æ¥å­˜æ”¾å™¨å®˜åæ ‡
        self.split = split
        self.npoint = npoint
        self.out_res = out_res
        self.geo = OrthogonalGeometry()
        self.preload = preload
        self.data_cache = []

        # --- ä¿ç•™ä½ åŸæ¥çš„æ–‡ä»¶åˆ’åˆ†é€»è¾‘ ---
        all_files = sorted(glob.glob(os.path.join(data_root, '*.npy')))
        n = len(all_files)
        # (æ­¤å¤„çœç•¥ä½ åŸæ¥çš„ 80/10/10 åˆ’åˆ†ä»£ç ï¼Œä¿æŒä¸å˜å³å¯)
        self.file_list = all_files # å‡è®¾å·²åˆ’åˆ†

        if self.preload:
            for path in tqdm(self.file_list, desc=f"[{split}] Pre-loading"):
                self.data_cache.append(np.load(path))

    def __len__(self):
        """è¿”å›æ•°æ®é›†æ ·æœ¬çš„æ€»æ•°"""
        return len(self.file_list)

    def eval_points_as_indices(self):
        """ç”Ÿæˆç”¨äºè¯„ä¼°çš„å…¨å›¾ç´¢å¼•ç½‘æ ¼"""
        res_x, res_y, res_z = self.out_res
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªç”Ÿæˆç´¢å¼•ï¼ŒçœŸæ­£çš„å½’ä¸€åŒ–å’Œ projection åœ¨ä¸‹é¢ç»Ÿä¸€åš
        grid = np.mgrid[:res_x, :res_y, :res_z]
        return grid.reshape(3, -1).transpose(1, 0) # [N, 3]

    def __getitem__(self, index):
        # 1. åŠ è½½å›¾åƒæ•°æ®
        if self.preload:
            vol_clean = self.data_cache[index]
            name = os.path.basename(self.file_list[index]).split('.')[0]
        else:
            path = self.file_list[index]
            name = os.path.basename(path).split('.')[0]
            vol_clean = np.load(path)

        res_x, res_y, res_z = self.out_res

        # 2. ğŸŸ¢ ã€æ ¸å¿ƒä¿®æ”¹ã€‘æå‰åŠ è½½ Mask æ ‡ç­¾ï¼
        label_path = os.path.join(self.label_root, f"{name}_label.npy")
        if os.path.exists(label_path):
            mask_np = np.load(label_path)
        else:
            print(f"\n[CRITICAL FATAL] æ‰¾ä¸åˆ°æ ‡ç­¾æ–‡ä»¶: {label_path}")
            mask_np = np.zeros_like(vol_clean) # å…œåº•

        # 3. æ¨¡æ‹Ÿ MR-Linac çš„ä¸‰å¸§æŠ•å½± (MIP)
        res_max = max(res_x, res_y, res_z)
        projs = np.zeros((3, 1, res_max, res_max), dtype=np.float32)
        projs[0, 0, :res_x, :res_y] = np.max(vol_clean, axis=2)
        projs[1, 0, :res_x, :res_z] = np.max(vol_clean, axis=1)
        projs[2, 0, :res_y, :res_z] = np.max(vol_clean, axis=0)

        # 4. ğŸŸ¢ å®æ—¶åŠ¨æ€é¶åŒºè®¡ç®— (å½»åº•æŠ›å¼ƒ JSON)
        if self.split == 'train':
            # ç›´æ¥ä» Mask ä¸­å¯»æ‰¾è‚è„çš„ç‰©ç†åæ ‡ (å‡è®¾ mask_np ä¸­ > 0 çš„å°±æ˜¯è‚è„)
            nz = np.argwhere(mask_np > 0)

            if len(nz) > 0:
                # åŠ¨æ€è·å– Z, Y, X (æˆ– X, Y, Zï¼Œå–å†³äº Numpy å­˜å‚¨é¡ºåº) çš„æå€¼
                mins = nz.min(axis=0)
                maxs = nz.max(axis=0)

                margin = 15 # 15 ä¸ªä½“ç´ çš„è„‚è‚ªç¼“å†²å¸¦

                # å®‰å…¨æˆªæ–­ï¼Œé˜²æ­¢è¶Šç•Œ
                min_0 = max(0, mins[0] - margin)
                max_0 = min(vol_clean.shape[0], maxs[0] + margin)
                min_1 = max(0, mins[1] - margin)
                max_1 = min(vol_clean.shape[1], maxs[1] + margin)
                min_2 = max(0, mins[2] - margin)
                max_2 = min(vol_clean.shape[2], maxs[2] + margin)

                # 100% ç®—åŠ›æ­»æ­»é”åœ¨è†¨èƒ€é¶åŒºå†…ï¼
                coords = np.stack([
                    np.random.randint(min_0, max_0, self.npoint),
                    np.random.randint(min_1, max_1, self.npoint),
                    np.random.randint(min_2, max_2, self.npoint)
                ], axis=1)
            else:
                # æç«¯å¼‚å¸¸å…œåº•ï¼šå¦‚æœè¿™å¼ åˆ‡ç‰‡é‡Œå®Œå…¨æ²¡æœ‰è‚è„
                coords = np.stack([
                    np.random.randint(0, res_x, self.npoint),
                    np.random.randint(0, res_y, self.npoint),
                    np.random.randint(0, res_z, self.npoint)
                ], axis=1)
        else:
            # æ¨ç†æ¨¡å¼ï¼šå…¨å›¾ç½‘æ ¼é‡‡æ ·
            coords = self.eval_points_as_indices()

            # 5. ç‰©ç†ç©ºé—´å½’ä¸€åŒ– [-1, 1]
        values = vol_clean[coords[:, 0], coords[:, 1], coords[:, 2]]
        res_array = np.array([res_x, res_y, res_z], dtype=np.float32)
        points_norm = ((coords.astype(np.float32) / (res_array - 1)) - 0.5) * 2

        proj_points = np.stack([
            self.geo.project(points_norm, 0),
            self.geo.project(points_norm, 1),
            self.geo.project(points_norm, 2)
        ], axis=0)

        return {
            'name': name,
            'projs': projs,
            'points': points_norm.astype(np.float32),
            'proj_points': proj_points.astype(np.float32),
            'p_gt': values[None, :].astype(np.float32),
            'image': vol_clean[None, ...],
            'mask': mask_np[None, ...]
        }